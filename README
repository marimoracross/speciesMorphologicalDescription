Semi-automatic Extraction of Plants Morphological Characters from Taxonomic Descriptions Written in Spanish

Maria Mora, José Araya 
Costa Rica Institute of Technology, School of Computer Engineering
Abstract

Taxonomic literature keeps records of the planet's biodiversity and gives access to the knowledge needed for its sustainable management. Unfortunately, most of the taxonomic information is available in scientific publications in text format. The amount of publications generated is very large; therefore to process it manually is a complex and very expensive activity. The Biodiversity Heritage Library (BHL) estimates that there are more than 120 million of pages published in over 5.4 million of books since 1469, plus about 800,000 monographs and 40,000 journal titles (12,500 of these are current) [6].

It is necessary to develop standards and software tools to extract and integrate this knowledge into existing free and open access repositories to support science, education, and biodiversity conservation.

This project presents an algorithm based on computational linguistics techniques to extract structured information from morphological descriptions of plants written in Spanish. The developed algorithm is based on the work of Dr. Hong Cui from the University of Arizona and was applied to the book Trees of Costa Rica Volume III (ACRv3) [8] and to a subset of descriptions of the Manual of Plants of Costa Rica (MPCR) with very competitive results (more than 94.1% of average performance) extracting structures, characters, associating characters to structures, and processing conjunctions. The implemented tool is free software, was developed using Java, and integrates existing technology as FreeLing [9], the Plant Ontology (PO) [10], the Ontology Term Organizer (OTO) [11], and the Flora Mesoamericana English-Spanish Glossary [12].

Keywords: Information Extraction, Natural Language Processing, Machine Learning, Biodiversity Informatics.
Project Requirements:

    Freeling 3.1
    PostgreSQL
    Eclipse
    Ubuntu 14.04 (trusty)

This site includes a copy of:

    The database structure (a PostgreSQL database backup)
    Results of processing more that 700 morphological description (XML files) (/examples).
    Graduation Project Documentation (Master's Degree in Computer Science) Costa Rica Institute of Technology, School of Computer Engineering, 2016 (Spanish)

How to Process a New Book?

The Entity - Relationship Diagram ERD shows the database entities used by the algorithm.
To process a new book:

    Create a new book record in table BOOK.

    Include a new record for each taxon description that is part of the new book (included in 1.). Use table (TAXON_DESCRIPTION).

    Delete all records from tables CLAUSE, CHUNK, TOKEN, BIOLOGICAL_ENTITY and CHARACTER.

    Run the algorithm.

    Results are included in BIOLOGICAL_ENTITY (name of the plant parts) and CHARACTER (characters associated to each plant part).

Algorithm:

The algorithm consists of the following stages:

Stage 1. Pre-processing of morphological descriptions texts.

Stage 2. Standardization and segmentation of the morphological descriptions in clauses and chunks.

Stage 3. Semi-automatic learning of structures names and characters states.

Stage 4. Translation of tokens into English to match entries in the PO.

Stage 5. Semantic annotation of the descriptions.

Stage 6. Generation of results in XML.
Description of each stage

Stage 1. Pre-processing of the Morphological Descriptions Texts. The text pre-processing consists of:

    Remove double and single quotes from the descriptions.
    Add a point at the end of all the descriptions (in case they do not have it), required by Freeling to segment the texts into clauses.

Stage 2. Standardization and Segmentation of the Descriptions in Clauses and Chunks. The morphological descriptions are segmented into clauses using the end point of a sentence, the colon, and the semicolon as separator. The clauses are constructed in a standardized way from tokens that are part of them, all written in lowercase letters and separated by an space. The CLAUSE table contains clauses associated with each description. Each clause must start with a structure name to be processed by the algorithm.

However, clauses should be simplified even further with the aim of analyzing it and correcting errors in dependency trees generated by Freeling. Each clause is segmented into chunks using the comma as a separator. For example, the following clause (T8L5) generated 12 chunks as presented in Table 1: T8L5: hojas simples , alternas , ( 8,5) 14,5-33 × ( 4) 6-14 cm , oblongas a obovadas , ápice redondeado , obtuso a abrupto-acuminado , base redondeada , obtusa , truncada o levemente subcordada , glabras en el haz y con una pubescencia tomentosa sedosa con tricomas fasciculados en el envés , margen entero , crenado o distalmente denticulado ;

    hojas simples
    alternas
    ( 8,5) 14,5-33 × ( 4) 6-14 cm
    oblongas a obovadas
    ápice redondeado
    obtuso a abrupto-acuminado
    base redondeada
    obtusa
    truncada o levemente subcordada
    glabras en el haz y con una pubescencia tomentosa sedosa con tricomas fasciculados en el envés
    margen entero
    crenado o distalmente denticulado

Table 1: List of chunks generated from clause T8L5 of the Quercus insignis description of the ACRv4 book.

The process of chunks standardization does the following:

    Delete spaces between hyphens and numbers. The numbers and hyphens must always be contiguous, for example it must be (-8) and not (- 8). Regular expressions are used to eliminate spaces.
    Delete hyphens between a number and the parentheses. In other words, cases like (6-) must be replaced as (6). The numbers in parentheses are used in the descriptions of plants to document atypical ranges (explained in Appendix IV of the Graduation Project Documentation).

Stage 3. Semi-automatic learning of structures names and characters states. The knowledge base is key to the proper functioning of the system because it typifies all structures, character states, and other knowledge of the application area. The content of the knowledge base is used to correct the role assigned by Freeling to the different tokens.

The knowledge base is updated during the learning process of the system, the user must at the end of the process, verify that the knowledge acquired by the system is correct. At the end of the process, the user performs the following tasks:

    Select the tokens that are used in the definition of areas in a particular book, for example, in "(8,5) 14,5-33 × (4) 6-14 cm" the token "×" must be defined as an area indicator (type = G).
    Select the names or adjectives that can act as modifiers of a structure. A modifier, according to Cui in [33], delimits the set of objects to which the characters and states apply. Example: in the phrase "ramitas jóvenes" the adjective young acts as a modifier since it restricts the scope of the "ramitas" to only young.
    Verify that the knowledge acquired has been correctly typed by the system.

The KNOWLEDGE table maintains the knowledge acquired by the system. The types of knowledge that can be included are listed below:

    E = Structure or substructure.
    A = State of a character, in many cases it is an adjective. For example "rounded", "obtuse" or "abrupt-acuminate".
    M = Structure modifiers. Examples: "adult", "young", "female" or "male".
    U = Unit of measurement. For example "cm.", "mm." Or "m."
    G = Area. Example "x" or "by".
    V = Verb. Example: "covers", "described" or "are".
    T = Character name. Example "height", "color" or "thickness".
    R = Constraints of structure or characters. They are usually adverbs like "frequently" or "longitudinally".

In order to successfully carry out the texts structuring, the process of tokenization and POS assignment made by Freeling must be very good. However, due to the semi-structured language of the descriptions, Freeling correctly assigned POS tags only to adverbs, determinants, pronouns, conjunctions, prepositions, numerals, and dates. The POS tags assigned to verbs, names, and adjectives should be revised and in some cases corrected. Performing this review process manually is very time-consuming, so a very simple rule-based learning algorithm was implemented. The algorithm uses bootstrapping to implement an incremental learning process without examples (described in the Graduation Project Documentation).

Stage-4. Translation of tokens into English. Ontologies are a very valuable and limited resource in the field of Biodiversity Informatics and among those that are available, not many manage translations of terms into Spanish. The Plant Ontology (PO) includes translations into Spanish in the form of synonyms, however, in this research it was decided to use OTO due to the great advantage it has of being a collaborative web application for experts to sort and organize their ontology terms. However, OTO does not integrate synonyms, so to match the character states with those included in OTO it was necessary to translate the terms using first Google Translator (with 82.5% success in the translation of the terms of the descriptions of the book ACRv4) and then the English-Spanish, Spanish-English Glossary for the Mesoamerican Flora was integrated into the system. At the end of the process, a user must manually translate the untranslated terms.

Stage 5. Semantic annotation of the descriptions.

The rules and conditions that guide the extraction process were defined from a morphosyntactic analysis performed on descriptions of the TCRv4 book [16]. Rules were derived when processing the most common types of grammatical structures used by authors, for instance name + adjective (e.g. "flores rojas / red flowers") used in more than 17.5% of chunks of the book and chunks with only one adjective (e.g. "deciduous / deciduous") used more than 12.5%.

The algorithm analyzes the role of each token and the dependencies between tokens in a chunk and creates or modifies the corresponding objects in a database. Three types of objects are generated: structures, characters, and relationships. Tokens that do not generate one of those type of objects are considered modifiers.  Chunks, that are part of the same clause, are processed from left to right. The order of processing is important because not all chunks include the structure to which the characters should be associated therefore the algorithm should look for it in previously processed chunks.

To associate each character with the correct structure or substructure, the algorithm uses the order of appearance of tokens and their concordance in gender and number. Fig.Structures and Characters states  shows structures (written in red), the characters states (in green), and the relationship between structures and characters (as arrow). In this example, the "simple", "alternate", "elliptic", and "narrow-elliptic to linear-elliptic" characters must be associated with the "leaves" structure; "acuminate" and "caudate or acute" to the "apex" substructure; and "caudate or obtuse" to the "base" structure; Nevertheless, "glabrous" must be associated with "leaves" because it does not match gender and number with the closest substructures (i.e. base). The structures "trichomes", "vein", and "underside" are part of prepositional phrases and the system does not process all the information in them; however, structures are extracted for subsequent use of them during the association process.

The algorithm does not extract all information available in taxon descriptions. It does not process all prepositional or verbal phrases, however, as a proof of concept, the prepositional phrases that begin with tokens "sin / without" or "con / with" are structured. The rest of prepositional or verbal phrases are only delimited as constraint_preposition and constraint_verb respectively. The XLM 250- Euonymus costarricensis.xml  shows an example of how the system structured a phrase that begin with "con / with".  The XML section includes a relationship named "con / with" from the structure "semillas / seeds" (ID=227247)  to the structure "arilo / aryl" (ID=2272248).

Stage 6. Generation of results in XML. The content of the database at the end of the process is presented as XML documents according to the scheme proposed by Cui . For each taxon description, a separate document is created.
